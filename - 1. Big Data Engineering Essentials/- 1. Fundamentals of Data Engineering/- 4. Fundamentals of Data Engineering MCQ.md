
# ğŸ“˜ Hadoop & Spark Quiz â€“ Quick Revision Guide

This document is a quick-fire revision guide and MCQ set covering the essentials of Hadoop and Spark. Designed for interviews, exams, and hands-on learning.

---

## âœ… QUESTION 1: What is the primary purpose of Hadoop?

- â—»ï¸ A. Real-time data processing  
- âœ… B. **Distributed storage and batch data processing**  
- â—»ï¸ C. Streaming data analysis  
- â—»ï¸ D. Graph data analysis  

### ğŸ“Œ Explanation:
Hadoop is built to **store and process massive datasets** across distributed clusters. It consists of:
- **HDFS (Hadoop Distributed File System)** for storage.
- **MapReduce** for batch processing of large volumes of data.

Use case: Log analysis, ETL pipelines, data archival.

---

## âœ… QUESTION 2: What is the storage layer in Hadoop called?

- â—»ï¸ A. YARN  
- âœ… B. **HDFS**  
- â—»ï¸ C. MapReduce  
- â—»ï¸ D. RDDs  

### ğŸ“Œ Explanation:
**HDFS (Hadoop Distributed File System)** is the core storage layer of Hadoop.  
It splits large files into blocks (default 128MB or 256MB) and stores them redundantly across nodes.

Fun fact: HDFS uses a **write-once, read-many** model.

---

## âœ… QUESTION 3: What makes Spark faster than Hadoop for certain tasks?

- â—»ï¸ A. Disk-based processing  
- â—»ï¸ B. Replication of data  
- â—»ï¸ C. Support for multiple programming languages  
- âœ… D. **In-memory processing**  

### âš¡ Explanation:
Apache Sparkâ€™s **in-memory computation model** avoids costly disk I/O after each processing step.

- Ideal for: Machine Learning, iterative algorithms, real-time analytics.
- Spark holds intermediate results in RAM â¤ boosts speed **10x to 100x** over Hadoop MapReduce.

---

## âœ… QUESTION 4: What is the primary unit of data processing in Spark?

- â—»ï¸ A. MapReduce jobs  
- â—»ï¸ B. HDFS blocks  
- âœ… C. **RDDs (Resilient Distributed Datasets)**  
- â—»ï¸ D. YARN containers  

### ğŸ“Œ Explanation:
**RDDs** are Sparkâ€™s fundamental data structure:
- Distributed, fault-tolerant collections of data.
- Enable **parallel operations** across a cluster.
- Allow **lazy transformations** and **in-memory caching**.

Use case: Data wrangling, transformations, parallel processing.

---

## âœ… QUESTION 5: Which feature makes Spark suitable for real-time data processing?

- â—»ï¸ A. MapReduce  
- âœ… B. **Spark Streaming**  
- â—»ï¸ C. HDFS replication  
- â—»ï¸ D. Fault tolerance  

### ğŸ’¡ Explanation:
**Spark Streaming** allows Spark to process **live data streams** in near real-time.

- Works with Kafka, Flume, sockets, etc.
- Breaks data into micro-batches.
- Integrates easily with MLlib, SQL, and GraphX for extended analytics.

---

## ğŸ§  Bonus Tips:
- ğŸ’¾ **Hadoop** = Reliable storage + batch analytics. Not ideal for real-time.
- âš™ï¸ **Spark** = Fast, versatile engine for batch, streaming, and machine learning.
- ğŸ§° **Use both** together: Hadoop as the storage backend + Spark for fast computation.

---

> âœ¨ *â€œMaster the tools that master data!â€*
